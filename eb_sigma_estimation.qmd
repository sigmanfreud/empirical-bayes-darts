---
title: "eb_sigma_estimation"
format: html
editor: visual
---

# Estimating variance of throws

## Preliminaries

First, we define the boundaries of the dartboard.

```{r}
# Define the dartboard parameters (in mm)
bullseye_inner_radius <- 12.7
bullseye_outer_radius <- 31.8
triple_ring_inner_radius <- 99
triple_ring_outer_radius <- 107
double_ring_inner_radius <- 162
double_ring_outer_radius <- 170
```

Next, we write a function to check which region of the board we're in.

```{r}
get_dartboard_region_vectorized <- function(x, y) {
  # Constants
  segment_numbers <- c(20, 1, 18, 4, 13, 6, 10, 15, 2, 17,
                       3, 19, 7, 16, 8, 11, 14, 9, 12, 5)
  segment_width <- 360 / 20

  bull_inner <- 6.35
  bull_outer <- 15.9
  triple_inner <- 99
  triple_outer <- 107
  double_inner <- 162
  double_outer <- 170

  r <- sqrt(x^2 + y^2)
  theta <- (90 - atan2(y, x) * 180 / pi) %% 360
  segment_idx <- floor(theta / segment_width) + 1
  segment <- segment_numbers[segment_idx]

  region <- character(length(x))

  region[r <= bull_inner] <- "Bull"
  region[r > bull_inner & r <= bull_outer] <- "Outer Bull"
  region[r > bull_outer & r <= triple_inner] <- paste0("Single (Inner) ", segment[r > bull_outer & r <= triple_inner])
  region[r > triple_inner & r <= triple_outer] <- paste0("T", segment[r > triple_inner & r <= triple_outer])
  region[r > triple_outer & r <= double_inner] <- paste0("Single (Outer) ", segment[r > triple_outer & r <= double_inner])
  region[r > double_inner & r <= double_outer] <- paste0("D", segment[r > double_inner & r <= double_outer])
  region[r > double_outer] <- "Miss"

  return(region)
}


```

Now, we can write a function that checks what region a point is in.

```{r}
is_inside_region_vectorized <- function(x, y, target_region) {
  regions <- get_dartboard_region_vectorized(x, y)
  return(regions == target_region)
}
```

Finally, we have an example as a sanity check.

```{r}
library(MASS)

estimate_probability_optimized <- function(mu, sigma, region, n_samples = 100000) {
  samples <- MASS::mvrnorm(n_samples, mu = mu, Sigma = diag(sigma^2, 2))
  x <- samples[, 1]
  y <- samples[, 2]
  regions <- get_dartboard_region_vectorized(x, y)
  return(mean(regions == region))
}

# Parameters
mu <- c(0, 0)     # Aiming at center
sigma <- 50       # Standard deviation

# Probabilities
prob_bull <- estimate_probability_optimized(mu, sigma, "Bull")
prob_triple_ring <- estimate_probability_pattern(mu, sigma, "^T")
prob_double_ring <- estimate_probability_pattern(mu, sigma, "^D")

# Print results
cat("Probability of landing in the bullseye:", prob_bull, "\n")
cat("Probability of landing in the triple ring:", prob_triple_ring, "\n")
cat("Probability of landing in the double ring:", prob_double_ring, "\n")
```

Now, we verify that the sum of the probabilities is close to $1$. First, we generate all regions.

```{r}
# Build the list of all 62 valid dartboard regions
generate_all_regions <- function() {
  numbers <- as.character(1:20)
  c(
    "Bull",
    "Outer Bull",
    paste0("Single (Inner) ", numbers),
    paste0("T", numbers),
    paste0("Single (Outer) ", numbers),
    paste0("D", numbers)
  )
}
```

Now, we just verify that our function works. Indeed, the sum of probabilities of landing on any region of the dartboard should be very close to $1$.

```{r}
library(MASS)

# Estimate the probabilities for all regions
estimate_all_probabilities <- function(mu, sigma, n_samples = 100000) {
  regions <- generate_all_regions()
  probs <- numeric(length(regions))

  samples <- MASS::mvrnorm(n_samples, mu = mu, Sigma = diag(sigma^2, 2))
  x <- samples[, 1]
  y <- samples[, 2]
  sampled_regions <- get_dartboard_region_vectorized(x, y)

  for (i in seq_along(regions)) {
    probs[i] <- mean(sampled_regions == regions[i])
  }

  names(probs) <- regions
  return(probs)
}

# Parameters
mu <- c(0, 0)
sigma <- 50
n_samples <- 100000

# Run
region_probs <- estimate_all_probabilities(mu, sigma, n_samples)

# Output
total_prob <- sum(region_probs)
cat("Total probability across all 62 regions:", total_prob, "\n")

# Check if close to 1
if (abs(total_prob - 1) < 0.01) {
  cat("✅ Sum is close to 1 (within Monte Carlo tolerance).\n")
} else {
  cat("⚠️ Warning: Sum is not close to 1 — something might be wrong.\n")
}

```

## Data generation

We gotta do this part....

## Prior Estimation

For now, we use a G-modeling approach, and assuming $\sigma_i \sim \chi_2^2(\alpha, \beta).$ For the EB step, it suffices to find the MLE estimates $\hat \alpha, \hat\beta.$

```{r}
library(MASS)
library(mvtnorm)
library(stats4)

# Define dartboard region classifier (as before)
get_dartboard_region_vectorized <- function(x, y) {
  segment_numbers <- c(20, 1, 18, 4, 13, 6, 10, 15, 2, 17,
                       3, 19, 7, 16, 8, 11, 14, 9, 12, 5)
  segment_width <- 360 / 20

  bull_inner <- 6.35
  bull_outer <- 15.9
  triple_inner <- 99
  triple_outer <- 107
  double_inner <- 162
  double_outer <- 170

  r <- sqrt(x^2 + y^2)
  theta <- (90 - atan2(y, x) * 180 / pi) %% 360
  segment_idx <- floor(theta / segment_width) + 1
  segment <- segment_numbers[segment_idx]

  region <- character(length(x))
  region[r <= bull_inner] <- "Bull"
  region[r > bull_inner & r <= bull_outer] <- "Outer Bull"
  region[r > bull_outer & r <= triple_inner] <- paste0("Single (Inner) ", segment[r > bull_outer & r <= triple_inner])
  region[r > triple_inner & r <= triple_outer] <- paste0("T", segment[r > triple_inner & r <= triple_outer])
  region[r > triple_outer & r <= double_inner] <- paste0("Single (Outer) ", segment[r > triple_outer & r <= double_inner])
  region[r > double_inner & r <= double_outer] <- paste0("D", segment[r > double_inner & r <= double_outer])
  region[r > double_outer] <- "Miss"

  return(region)
}

# Monte Carlo estimate of p(Z | theta)
estimate_region_probability <- function(mu, theta, target_region, n_samples = 50) {
  sigma <- sqrt(theta)
  samples <- MASS::mvrnorm(n_samples, mu = mu, Sigma = diag(sigma^2, 2))
  regions <- get_dartboard_region_vectorized(samples[,1], samples[,2])
  mean(regions == target_region)
}

# Log-likelihood function for MLE over (a, b)
log_likelihood_ab <- function(a, b, observed_regions, mu, target_region, n_theta_samples = 50, n_mc_samples = 50) {
  if (a <= 0 || b <= 0) return(-Inf)

  # Sample theta from inverse-chi-squared(a, b)
  theta_samples <- b / rchisq(n_theta_samples, df = a)
  region_probs <- sapply(theta_samples, function(theta) {
    estimate_region_probability(mu, theta, target_region, n_mc_samples)
  })
  region_probs <- pmax(region_probs, 1e-12)  # Avoid log(0)

  # Approximate marginal likelihood
  avg_prob <- mean(region_probs)
  logL <- sum(log(rep(avg_prob, length(observed_regions))))

  return(logL)
}

# Wrapper for stats4::mle
mle_ab <- function(observed_regions, mu, target_region) {
  neg_log_likelihood <- function(a, b) {
    -log_likelihood_ab(a, b, observed_regions, mu, target_region)
  }

  mle_result <- mle(neg_log_likelihood, start = list(a = 5, b = 1000), method = "L-BFGS-B", lower = c(0.1, 0.1))
  return(mle_result)
}



```

For now, I'm only doing 50 iterations. Should probably increase this amount. We show an example.

```{r}
# Example usage:
set.seed(123)
mu_T20 <- c(0, 107)
observed_regions <- rep("T20", 15)  # Example data

mle_result <- mle_ab(observed_regions, mu_T20, "T20")
summary(mle_result)
```

## Likelihood Estimation

Now, we estimate the prior. We have to rely on MC methods.

```{r}

library(MASS)
library(ggplot2)

# Vectorized region probability computation
compute_region_probabilities <- function(mu, sigma, n_samples = 100000) {
  samples <- MASS::mvrnorm(n_samples, mu = mu, Sigma = diag(sigma^2, 2))
  x <- samples[, 1]
  y <- samples[, 2]
  regions <- get_dartboard_region_vectorized(x, y)
  table_regions <- table(regions)
  prob_regions <- as.numeric(table_regions) / n_samples
  names(prob_regions) <- names(table_regions)
  return(prob_regions)
}

# Likelihood computation (returns exp(log-likelihood))
likelihood_montecarlo <- function(mu, sigma, observed_counts, n_samples = 100000, tol = 1e-12) {
  region_probs <- compute_region_probabilities(mu, sigma, n_samples)
  likelihood <- 1
  for (region in names(observed_counts)) {
    prob <- region_probs[region]
    if (is.na(prob) || prob < tol) prob <- tol  # Apply tolerance
    likelihood <- likelihood * (prob ^ observed_counts[region])
  }
  return(likelihood)
}

# Define observed data
observed_counts <- c("T20" = 15, "Single (Outer) 20" = 48, "Single (Outer) 1" = 3)

# Approximate center of T20 (adjust as needed)
mu_T20 <- c(0, 107)

# Evaluate likelihood over a range of sigma
sigma_vals <- seq(10, 125, length.out = 100)  # Avoid sigma = 0 to prevent degenerate cases
likelihood_vals <- sapply(sigma_vals, function(s) {
  likelihood_montecarlo(mu = mu_T20, sigma = s, observed_counts = observed_counts)
})

# Normalize likelihoods for plotting (optional)
likelihood_vals <- likelihood_vals / max(likelihood_vals)




```

Now, we plot.

```{r}
# Plot
df <- data.frame(sigma = sigma_vals, likelihood = likelihood_vals)
ggplot(df, aes(x = sigma, y = likelihood)) +
  geom_line(color = "darkgreen") +
  labs(title = "Likelihood vs. Sigma (Aiming at T20)",
       x = expression(sigma),
       y = "Normalized Likelihood") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

## Posterior Estimation

Just multiply the likelihood with the posterior and normalize.

```{r}

library(pracma)  # For trapz() to numerically integrate

# Assume: sigma_vals, logL_vals, and likelihood_vals are already computed

# Convert sigma^2 to theta (variance parameter)
theta_vals <- sigma_vals^2

# Define Inverse Chi-Squared density (same as before)
dinvchisq <- function(theta, a, b) {
  const <- (b/2)^(a/2) / gamma(a/2)
  const * theta^(-(a/2 + 1)) * exp(-b / (2 * theta))
}



# Evaluate prior at theta values
prior_vals <- dinvchisq(theta_vals, 5, 1000)

# Compute unnormalized posterior
unnormalized_posterior <- likelihood_vals * prior_vals

# Normalize posterior
posterior_vals <- unnormalized_posterior / trapz(theta_vals, unnormalized_posterior)

# Plot posterior
plot(theta_vals, posterior_vals, type = "l", lwd = 2, col = "purple",
     main = "Posterior Distribution of Theta",
     xlab = expression(theta), ylab = "Posterior Density")

```
